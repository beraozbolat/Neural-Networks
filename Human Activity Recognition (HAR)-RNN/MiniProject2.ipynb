{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('data-Mini Project 2.h5', 'r') as file:\n",
    "    # List all the groups in the file\n",
    "    trX = file['trX'][:]\n",
    "    testdata = file['tstX'][:]\n",
    "    trY = file['trY'][:]\n",
    "    testlabel = file['tstY'][:]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAR:\n",
    "\n",
    "    def initilaze(self,hidden_size,learning_rate):\n",
    "        \n",
    "        self.IH_weight = np.random.uniform(-0.01, 0.01, size=(hidden_size, 4))\n",
    "        self.HH_weight = np.random.uniform(-0.01, 0.01, size=(hidden_size, hidden_size))\n",
    "        self.OH_weight = np.random.uniform(-0.01, 0.01, size=(6, hidden_size+1))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.hidden_size = hidden_size\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def forward_propagation(self,datas,labels,batch_size):\n",
    "        EPSILON = 1e-10\n",
    "        grad_HO = 0\n",
    "        cost = 0\n",
    "        h_list = np.zeros((self.batch_size,1,self.hidden_size))\n",
    "        input_list = np.zeros((self.batch_size,1,4))\n",
    "        output_list = np.zeros((self.batch_size,1,6))  \n",
    "        feedback=np.zeros((self.hidden_size,1))\n",
    "        error=0.0\n",
    "        correct_predictions=0\n",
    "        for i in range(self.batch_size):\n",
    "            data=datas[i].reshape(1,4)\n",
    "            input_list[i]=data\n",
    "            v_1= np.dot(self.IH_weight,data.T) + np.dot(self.HH_weight.T,feedback)\n",
    "            h_i=self.Tanh_activation(v_1)\n",
    "            feedback=h_i\n",
    "            h_list[i]=feedback.T\n",
    "            bias=-1 * np.ones((1, 1))\n",
    "            biased_h_i=np.concatenate((h_i.T,bias),axis=1)\n",
    "            y_input = biased_h_i\n",
    "            v_2= np.dot(self.OH_weight,y_input.T)\n",
    "            output=self.sigmoid_activation(v_2)\n",
    "            labels=labels.reshape(6,1)\n",
    "            correct_predictions += np.sum(np.argmax(output, axis=0) == np.argmax(labels, axis=0))\n",
    "            grad_HO +=  np.dot((output-labels), biased_h_i)\n",
    "            error += -labels * np.log10(np.clip(output, EPSILON, 1 - EPSILON)) -(1 - labels) * np.log10(np.clip(1 - output, EPSILON, 1 - EPSILON))\n",
    "\n",
    "            output_list[i]=output.T\n",
    "\n",
    "        return h_list,output_list,error,grad_HO,input_list,output,correct_predictions\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def gradient(self,y_n,d_n,h_list,x_list): #BPTT algorithm for updating WIH and WHH\n",
    "        #h_list = [h0,h1,....,hn]\n",
    "        h_n = h_list[-1]\n",
    "    \n",
    "        common = np.dot((y_n.T - d_n),self.OH_weight [:, :-1]) # 1x6 @ 6xN -> 1xN\n",
    "    \n",
    "        initial_term = common * (1-h_n**2)\n",
    "    \n",
    "        h_list = h_list[:-1] #Removing the h_n data from the list for convention\n",
    "    \n",
    "        index = 0\n",
    "        grad_HH = np.zeros((self.hidden_size ,self.hidden_size))\n",
    "        grad_IH = np.zeros((self.hidden_size,4))\n",
    "        grad_bias1 = 0\n",
    "    \n",
    "        #Implementation of the derivative chain\n",
    "        for i in reversed(range(1,len(h_list))): # i = n-1,n-2 .... , 0\n",
    "            term = initial_term\n",
    "            for j in range(len(h_list)-1,len(h_list)-index-1,-1): # j = n-1,....,n-1-index\n",
    "    \n",
    "                term = np.dot(term,self.HH_weight) * (1-h_list[j]**2) #term = (term @ WHH) * h[j]\n",
    "    \n",
    "            grad_HH += np.dot(term.T,h_list[i])\n",
    "            #print(\"Delta Grad_HH:\",np.dot((common * term).T,h_list[i]))\n",
    "            grad_IH += np.dot( term.T,x_list[i])\n",
    "            grad_bias1 += np.mean( term * -1)\n",
    "            index += 1\n",
    "\n",
    "        return grad_IH,grad_HH \n",
    "        \n",
    "    \n",
    "    def output_backward(self,dWoh):\n",
    "        \n",
    "        self.OH_weight= self.OH_weight + self.learning_rate*dWoh\n",
    "    \n",
    "    def hh_backward(self,gradient_list):\n",
    "        self.HH_weight = self.HH_weight + self.learning_rate*gradient_list\n",
    "        \n",
    "    def IH_backward(self,gradient_list):\n",
    "        self.IH_weight = self.IH_weight + self.learning_rate*gradient_list\n",
    "        \n",
    "    def Train(self,data,label,batch_size):\n",
    "        startTime = time.time()\n",
    "        correct_predictions2=0\n",
    "        total=0\n",
    "        correct_predictions3=0\n",
    "        self.batch_size=batch_size\n",
    "        for epoch in range(15):\n",
    "            print(\"epoch: \", epoch + 1)\n",
    "            cum_error=0.0\n",
    "            \n",
    "            correct_predictions2=0\n",
    "            for idx in range(1500,2000):\n",
    "                sample_data=data[idx,:,:]\n",
    "                bias=-1 * np.ones((sample_data.shape[0], 1))\n",
    "                biased_sample=np.hstack((sample_data,bias))\n",
    "                self.batch_error=0.0\n",
    "                correct_predictions1=0\n",
    "                for time_idx in range(int(150/self.batch_size)):\n",
    "                    total+=self.batch_size\n",
    "                    datas=biased_sample[int(self.batch_size*time_idx):int(self.batch_size*(time_idx+1))]\n",
    "                    labels=label[idx]\n",
    "                    h_list,output_list,error,grad_HO,input_list,output,correct_predictions=self.forward_propagation(datas, labels,self.batch_size)\n",
    "                    self.batch_error+=np.sum(error)\n",
    "                    correct_predictions1+=correct_predictions\n",
    "                    self.delta_weights=np.zeros((6, 50))                    \n",
    "                    \n",
    "                    grad_IH,grad_HH=self.gradient(output,labels,h_list,input_list)\n",
    "                    max_gradient_norm = 0.5 \n",
    "            \n",
    "                    grad_HO_clipped = np.clip(grad_HO, -max_gradient_norm, max_gradient_norm)\n",
    "                    grad_HH_clipped = np.clip(grad_HH, -max_gradient_norm, max_gradient_norm)\n",
    "                    grad_IH_clipped = np.clip(grad_IH, -max_gradient_norm, max_gradient_norm)\n",
    "                    self.OH_weight -= self.learning_rate * grad_HO/batch_size\n",
    "                    self.HH_weight -= self.learning_rate * grad_HH_clipped/batch_size\n",
    "                    self.IH_weight -= self.learning_rate * grad_IH_clipped/batch_size\n",
    "                    \n",
    "                #self.batch_error=(self.batch_error/batch_size)\n",
    "                correct_predictions2+=correct_predictions1\n",
    "                cum_error+=np.sum((self.batch_error/50))\n",
    "                #print(\"Epoch error {i} {error}\".format(i=epoch,error=batch_error))\n",
    "            correct_predictions3+=correct_predictions2\n",
    "            print(\"Error per epoch\",cum_error)\n",
    "        print(\"Train error %\",100*correct_predictions3/total)\n",
    "\n",
    "        \n",
    "    def Tanh_activation(self,x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def sigmoid_activation(self,x):\n",
    "        y = expit(x)\n",
    "        return y\n",
    "    \n",
    "    def Tanh_activation_derivative(self,x):\n",
    "        return (1/2)*(1-x*x)\n",
    "    \n",
    "    def sigmoid_activation_derivative(self,x):\n",
    "        return x-x*x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "deneme1=HAR()\n",
    "deneme1.initilaze(50,0.001)\n",
    "deneme1.Train(trX,trY,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "1950.5248699185024\n",
      "epoch:  2\n",
      "1610.6879933208184\n",
      "epoch:  3\n",
      "1564.5489289495458\n",
      "epoch:  4\n",
      "1544.0201927502824\n",
      "epoch:  5\n",
      "1518.5805863518503\n",
      "epoch:  6\n",
      "1475.980698401798\n",
      "epoch:  7\n",
      "1425.9856035754024\n",
      "epoch:  8\n",
      "1387.6667568529242\n",
      "epoch:  9\n",
      "1360.1865309432467\n",
      "epoch:  10\n",
      "1337.9654785427108\n",
      "epoch:  11\n",
      "1319.3357566487107\n",
      "epoch:  12\n",
      "1304.607414602222\n",
      "epoch:  13\n",
      "1293.8634890966014\n",
      "epoch:  14\n",
      "1286.4343596622869\n",
      "epoch:  15\n",
      "1281.7970699907896\n"
     ]
    }
   ],
   "source": [
    "deneme1.Train(trX,trY,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_test(W_hh,W_oh,W_ih,hidden_size): \n",
    "    top1 = 0\n",
    "    top2 = 0\n",
    "    top3 = 0\n",
    "    misclass = 0\n",
    "    total = 0\n",
    "    feedback = np.zeros((1,hidden_size))\n",
    "    for test_idx in range(len(testdata)):\n",
    "        test_data_idx = testdata[test_idx]\n",
    "        for time_idx in range(150):\n",
    "            test_reshaped = np.reshape(test_data_idx[time_idx], (1,3))\n",
    "            biased_data = np.append(test_reshaped,-1)\n",
    "            biased_data = np.reshape(biased_data, (1,4))#reshape biased data\n",
    "            v_t = np.dot(biased_data, W_ih.T) + np.dot(feedback, W_hh.T)\n",
    "            h_test = tanh(v_t)\n",
    "            feedback = h_test\n",
    "            biased_feedback = np.append(h_test,-1)\n",
    "            v_ot = np.dot(biased_feedback, W_oh.T)\n",
    "            output = sigmoid(v_ot)\n",
    "            output = np.reshape(output, (1,6))\n",
    "            desired = testlabel[test_idx]\n",
    "            desired = np.reshape(desired, (1,6))\n",
    "            output_list1 = output.copy()\n",
    "            output_list1 = np.reshape(output_list1, np.shape(output))\n",
    "            output_list1[0,np.argmax(output_list1)] = -9999999999999999\n",
    "            output_list2 = output_list1.copy()\n",
    "            output_list2 = np.reshape(output_list2, np.shape(output))\n",
    "            output_list2[0,np.argmax(output_list2)] = -9999999999999999\n",
    "            if np.argmax(output) == np.argmax(desired):\n",
    "                total += 1\n",
    "                top1 += 1\n",
    "                top2 += 1\n",
    "                top3 += 1\n",
    "            elif np.argmax(output_list1) == np.argmax(desired):\n",
    "                total += 1\n",
    "                #print(oi_test)\n",
    "                top2 += 1\n",
    "                top3 += 1\n",
    "            elif np.argmax(output_list2) == np.argmax(desired):\n",
    "                total += 1\n",
    "                top3 += 1\n",
    "            else:\n",
    "                total += 1\n",
    "                misclass += 1 \n",
    "    print(\"Top-1 Accuracy: %\", 100*(top1/total))\n",
    "    print(\"Top-2 Accuracy: %\", 100*(top2/total))\n",
    "    print(\"Top-3 Accuracy: %\", 100*(top3/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hh=deneme1.HH_weight\n",
    "W_oh =deneme1.OH_weight\n",
    "W_ih =deneme1.IH_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA SHUFFLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = np.random.permutation(trX.shape[0])\n",
    "shuffled_train_data = trX\n",
    "shuffled_labels = trY\n",
    "for old, new in enumerate(permutation):\n",
    "    shuffled_train_data[new,:,:] = trX[old,:,:]\n",
    "    shuffled_labels[new,:] = trY[old,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return expit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 1 N=50 BATCH 10 ,0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "Error per epoch 1940.3132243269904\n",
      "epoch:  2\n",
      "Error per epoch 1593.3346315128456\n",
      "epoch:  3\n",
      "Error per epoch 1547.2351086744854\n",
      "epoch:  4\n",
      "Error per epoch 1528.4298258524652\n",
      "epoch:  5\n",
      "Error per epoch 1507.7409714516004\n",
      "epoch:  6\n",
      "Error per epoch 1475.2579638034877\n",
      "epoch:  7\n",
      "Error per epoch 1437.0342434119375\n",
      "epoch:  8\n",
      "Error per epoch 1408.1719927551696\n",
      "epoch:  9\n",
      "Error per epoch 1388.9179088904132\n",
      "epoch:  10\n",
      "Error per epoch 1373.5041157467656\n",
      "epoch:  11\n",
      "Error per epoch 1359.602601467533\n",
      "epoch:  12\n",
      "Error per epoch 1347.2231923316424\n",
      "epoch:  13\n",
      "Error per epoch 1336.945229408092\n",
      "epoch:  14\n",
      "Error per epoch 1328.70823659169\n",
      "epoch:  15\n",
      "Error per epoch 1321.820344489645\n",
      "Train error % 32.78305185185185\n"
     ]
    }
   ],
   "source": [
    "deneme1=HAR()\n",
    "deneme1.initilaze(50,0.001)\n",
    "deneme1.Train(trX,trY,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hh=deneme1.HH_weight\n",
    "W_oh =deneme1.OH_weight\n",
    "W_ih =deneme1.IH_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 36.08\n",
      "Top-2 Accuracy: % 47.92111111111111\n",
      "Top-3 Accuracy: % 61.577777777777776\n"
     ]
    }
   ],
   "source": [
    "data_test(W_hh,W_oh,W_ih,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 2 N=50 BATCH 10 ,0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "Error per epoch 1621.8849175879932\n",
      "epoch:  2\n",
      "Error per epoch 1418.057827026871\n",
      "epoch:  3\n",
      "Error per epoch 1328.9554127958272\n",
      "epoch:  4\n",
      "Error per epoch 1307.0557398230949\n",
      "epoch:  5\n",
      "Error per epoch 1348.657881609049\n",
      "epoch:  6\n",
      "Error per epoch 1280.3700787824341\n",
      "epoch:  7\n",
      "Error per epoch 1260.8777955878259\n",
      "epoch:  8\n",
      "Error per epoch 1215.828987453146\n",
      "epoch:  9\n",
      "Error per epoch 1192.5523268180889\n",
      "epoch:  10\n",
      "Error per epoch 1176.3022187086533\n",
      "epoch:  11\n",
      "Error per epoch 1154.112222812193\n",
      "epoch:  12\n",
      "Error per epoch 1165.7123897352474\n",
      "epoch:  13\n",
      "Error per epoch 1153.7867189039075\n",
      "epoch:  14\n",
      "Error per epoch 1141.0490663684927\n",
      "epoch:  15\n",
      "Error per epoch 1132.5750319011731\n",
      "Train error % 37.92302222222222\n"
     ]
    }
   ],
   "source": [
    "deneme2=HAR()\n",
    "deneme2.initilaze(50,0.005)\n",
    "deneme2.Train(trX,trY,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 14.974444444444446\n",
      "Top-2 Accuracy: % 33.452222222222225\n",
      "Top-3 Accuracy: % 49.55777777777778\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme2.HH_weight,deneme2.OH_weight,deneme2.IH_weight,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 3 N=50 BATCH 30 ,0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "Error per epoch 2278.8974677871724\n",
      "epoch:  2\n",
      "Error per epoch 1850.7387374591926\n",
      "epoch:  3\n",
      "Error per epoch 1694.583858089481\n",
      "epoch:  4\n",
      "Error per epoch 1625.4005656503614\n",
      "epoch:  5\n",
      "Error per epoch 1590.0484664975895\n",
      "epoch:  6\n",
      "Error per epoch 1569.9766139123933\n",
      "epoch:  7\n",
      "Error per epoch 1557.6102424464702\n",
      "epoch:  8\n",
      "Error per epoch 1549.463851821298\n",
      "epoch:  9\n",
      "Error per epoch 1543.774956172293\n",
      "epoch:  10\n",
      "Error per epoch 1539.580297816693\n",
      "epoch:  11\n",
      "Error per epoch 1536.316855359404\n",
      "epoch:  12\n",
      "Error per epoch 1533.6346812826223\n",
      "epoch:  13\n",
      "Error per epoch 1531.302787570074\n",
      "epoch:  14\n",
      "Error per epoch 1529.1589083333834\n",
      "epoch:  15\n",
      "Error per epoch 1527.0812670071848\n",
      "Train error % 231.49653333333333\n"
     ]
    }
   ],
   "source": [
    "deneme3=HAR()\n",
    "deneme3.initilaze(50,0.001)\n",
    "deneme3.Train(trX,trY,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 16.666666666666664\n",
      "Top-2 Accuracy: % 33.33333333333333\n",
      "Top-3 Accuracy: % 50.0\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme3.HH_weight,deneme3.OH_weight,deneme3.IH_weight,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 4 N=50 BATCH 30 ,0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "Error per epoch 1806.7996778131726\n",
      "epoch:  2\n",
      "Error per epoch 1551.6180916069538\n",
      "epoch:  3\n",
      "Error per epoch 1530.9721156725852\n",
      "epoch:  4\n",
      "Error per epoch 1518.5360379986118\n",
      "epoch:  5\n",
      "Error per epoch 1498.9588032939348\n",
      "epoch:  6\n",
      "Error per epoch 1467.8820669943323\n",
      "epoch:  7\n",
      "Error per epoch 1434.2708140661987\n",
      "epoch:  8\n",
      "Error per epoch 1409.5023843777483\n",
      "epoch:  9\n",
      "Error per epoch 1393.2019385031128\n",
      "epoch:  10\n",
      "Error per epoch 1380.8120085275923\n",
      "epoch:  11\n",
      "Error per epoch 1370.1913634241746\n",
      "epoch:  12\n",
      "Error per epoch 1361.143765672337\n",
      "epoch:  13\n",
      "Error per epoch 1354.0294315814097\n",
      "epoch:  14\n",
      "Error per epoch 1348.881296042328\n",
      "epoch:  15\n",
      "Error per epoch 1345.2262627075554\n",
      "Train error % 295.088\n"
     ]
    }
   ],
   "source": [
    "deneme4=HAR()\n",
    "deneme4.initilaze(50,0.005)\n",
    "deneme4.Train(trX,trY,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 35.66777777777778\n",
      "Top-2 Accuracy: % 47.43555555555555\n",
      "Top-3 Accuracy: % 59.21666666666666\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme4.HH_weight,deneme4.OH_weight,deneme4.IH_weight,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 5 N=100 BATCH 10 ,0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "Error per epoch 1940.4782160716336\n",
      "epoch:  2\n",
      "Error per epoch 1591.7860472366467\n",
      "epoch:  3\n",
      "Error per epoch 1544.0674167426935\n",
      "epoch:  4\n",
      "Error per epoch 1521.3313822051243\n",
      "epoch:  5\n",
      "Error per epoch 1493.1501908996602\n",
      "epoch:  6\n",
      "Error per epoch 1453.436715670124\n",
      "epoch:  7\n",
      "Error per epoch 1415.8412628519848\n",
      "epoch:  8\n",
      "Error per epoch 1389.9308848318187\n",
      "epoch:  9\n",
      "Error per epoch 1371.0342066120454\n",
      "epoch:  10\n",
      "Error per epoch 1356.2251941258278\n",
      "epoch:  11\n",
      "Error per epoch 1345.2782392147296\n",
      "epoch:  12\n",
      "Error per epoch 1337.598279630093\n",
      "epoch:  13\n",
      "Error per epoch 1331.808201057402\n",
      "epoch:  14\n",
      "Error per epoch 1326.8442281705163\n",
      "epoch:  15\n",
      "Error per epoch 1322.6330752592175\n",
      "Train error % 33.477866666666664\n"
     ]
    }
   ],
   "source": [
    "deneme5=HAR()\n",
    "deneme5.initilaze(100,0.001)\n",
    "deneme5.Train(trX,trY,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 36.09222222222222\n",
      "Top-2 Accuracy: % 48.19111111111111\n",
      "Top-3 Accuracy: % 61.55666666666667\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme5.HH_weight,deneme5.OH_weight,deneme5.IH_weight,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 6 N=100 BATCH 10 ,0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "Error per epoch 1613.5021356542456\n",
      "epoch:  2\n",
      "Error per epoch 1390.2855078976404\n",
      "epoch:  3\n",
      "Error per epoch 1327.2425567802304\n",
      "epoch:  4\n",
      "Error per epoch 1240.2092797308396\n",
      "epoch:  5\n",
      "Error per epoch 1107.9580006557865\n",
      "epoch:  6\n",
      "Error per epoch 1072.1294372650798\n",
      "epoch:  7\n",
      "Error per epoch 1066.0208207613493\n",
      "epoch:  8\n",
      "Error per epoch 1056.6769513352451\n",
      "epoch:  9\n",
      "Error per epoch 1046.0505763695983\n",
      "epoch:  10\n",
      "Error per epoch 1035.6190358225413\n",
      "epoch:  11\n",
      "Error per epoch 1025.9073216085535\n",
      "epoch:  12\n",
      "Error per epoch 1008.5360424772206\n",
      "epoch:  13\n",
      "Error per epoch 992.1891118108983\n",
      "epoch:  14\n",
      "Error per epoch 991.5417734640134\n",
      "epoch:  15\n",
      "Error per epoch 1005.3300613264378\n",
      "Train error % 41.21078518518519\n"
     ]
    }
   ],
   "source": [
    "deneme6=HAR()\n",
    "deneme6.initilaze(100,0.005)\n",
    "deneme6.Train(trX,trY,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 16.634444444444444\n",
      "Top-2 Accuracy: % 37.315555555555555\n",
      "Top-3 Accuracy: % 50.0\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme6.HH_weight,deneme6.OH_weight,deneme6.IH_weight,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 7 N=100 BATCH 30 ,0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "Error per epoch 2281.8821744287097\n",
      "epoch:  2\n",
      "Error per epoch 1850.8624513506875\n",
      "epoch:  3\n",
      "Error per epoch 1693.9284864065662\n",
      "epoch:  4\n",
      "Error per epoch 1624.4117884418824\n",
      "epoch:  5\n",
      "Error per epoch 1588.813328321387\n",
      "epoch:  6\n",
      "Error per epoch 1568.48680880142\n",
      "epoch:  7\n",
      "Error per epoch 1555.825500816089\n",
      "epoch:  8\n",
      "Error per epoch 1547.32842340314\n",
      "epoch:  9\n",
      "Error per epoch 1541.2212687666893\n",
      "epoch:  10\n",
      "Error per epoch 1536.5287396278052\n",
      "epoch:  11\n",
      "Error per epoch 1532.6743458513704\n",
      "epoch:  12\n",
      "Error per epoch 1529.2929429121496\n",
      "epoch:  13\n",
      "Error per epoch 1526.1367411762908\n",
      "epoch:  14\n",
      "Error per epoch 1523.0255278853626\n",
      "epoch:  15\n",
      "Error per epoch 1519.819292933373\n",
      "Train error % 231.19946666666667\n"
     ]
    }
   ],
   "source": [
    "deneme7=HAR()\n",
    "deneme7.initilaze(100,0.001)\n",
    "deneme7.Train(trX,trY,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 16.666666666666664\n",
      "Top-2 Accuracy: % 33.33333333333333\n",
      "Top-3 Accuracy: % 50.0\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme7.HH_weight,deneme7.OH_weight,deneme7.IH_weight,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 8 N=100 BATCH 30 ,0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "Error per epoch 1805.8289502502103\n",
      "epoch:  2\n",
      "Error per epoch 1550.2816194859645\n",
      "epoch:  3\n",
      "Error per epoch 1528.1988079122243\n",
      "epoch:  4\n",
      "Error per epoch 1512.7479159961695\n",
      "epoch:  5\n",
      "Error per epoch 1488.4468942663784\n",
      "epoch:  6\n",
      "Error per epoch 1453.6666340541199\n",
      "epoch:  7\n",
      "Error per epoch 1420.5713705328005\n",
      "epoch:  8\n",
      "Error per epoch 1397.6858941209548\n",
      "epoch:  9\n",
      "Error per epoch 1381.9218574657577\n",
      "epoch:  10\n",
      "Error per epoch 1370.0129577601256\n",
      "epoch:  11\n",
      "Error per epoch 1361.1439923494806\n",
      "epoch:  12\n",
      "Error per epoch 1354.8874844471134\n",
      "epoch:  13\n",
      "Error per epoch 1350.4820231674148\n",
      "epoch:  14\n",
      "Error per epoch 1347.1156328406191\n",
      "epoch:  15\n",
      "Error per epoch 1344.2476113159817\n",
      "Train error % 300.96586666666667\n"
     ]
    }
   ],
   "source": [
    "deneme8=HAR()\n",
    "deneme8.initilaze(100,0.005)\n",
    "deneme8.Train(trX,trY,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 35.68333333333334\n",
      "Top-2 Accuracy: % 47.06777777777778\n",
      "Top-3 Accuracy: % 57.544444444444444\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme8.HH_weight,deneme8.OH_weight,deneme8.IH_weight,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL DATA BATCH 10 LR 0.001 HS=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAR2:\n",
    "\n",
    "    def initilaze(self,hidden_size,learning_rate):\n",
    "        \n",
    "        self.IH_weight = np.random.uniform(-0.01, 0.01, size=(hidden_size, 4))\n",
    "        self.HH_weight = np.random.uniform(-0.01, 0.01, size=(hidden_size, hidden_size))\n",
    "        self.OH_weight = np.random.uniform(-0.01, 0.01, size=(6, hidden_size+1))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.hidden_size = hidden_size\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def forward_propagation(self,datas,labels,batch_size):\n",
    "        EPSILON = 1e-10\n",
    "        grad_HO = 0\n",
    "        cost = 0\n",
    "        h_list = np.zeros((self.batch_size,1,self.hidden_size))\n",
    "        input_list = np.zeros((self.batch_size,1,4))\n",
    "        output_list = np.zeros((self.batch_size,1,6))  \n",
    "        feedback=np.zeros((self.hidden_size,1))\n",
    "        error=0.0\n",
    "        correct_predictions=0\n",
    "        for i in range(self.batch_size):\n",
    "            data=datas[i].reshape(1,4)\n",
    "            input_list[i]=data\n",
    "            v_1= np.dot(self.IH_weight,data.T) + np.dot(self.HH_weight.T,feedback)\n",
    "            h_i=self.Tanh_activation(v_1)\n",
    "            feedback=h_i\n",
    "            h_list[i]=feedback.T\n",
    "            bias=-1 * np.ones((1, 1))\n",
    "            biased_h_i=np.concatenate((h_i.T,bias),axis=1)\n",
    "            y_input = biased_h_i\n",
    "            v_2= np.dot(self.OH_weight,y_input.T)\n",
    "            output=self.sigmoid_activation(v_2)\n",
    "            labels=labels.reshape(6,1)\n",
    "            correct_predictions += np.sum(np.argmax(output, axis=0) == np.argmax(labels, axis=0))\n",
    "            grad_HO +=  np.dot((output-labels), biased_h_i)\n",
    "            error += -labels * np.log10(np.clip(output, EPSILON, 1 - EPSILON)) -(1 - labels) * np.log10(np.clip(1 - output, EPSILON, 1 - EPSILON))\n",
    "\n",
    "            output_list[i]=output.T\n",
    "\n",
    "        return h_list,output_list,error,grad_HO,input_list,output,correct_predictions\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def gradient(self,y_n,d_n,h_list,x_list): #BPTT algorithm for updating WIH and WHH\n",
    "        #h_list = [h0,h1,....,hn]\n",
    "        h_n = h_list[-1]\n",
    "    \n",
    "        common = np.dot((y_n.T - d_n),self.OH_weight [:, :-1]) # 1x6 @ 6xN -> 1xN\n",
    "    \n",
    "        initial_term = common * (1-h_n**2)\n",
    "    \n",
    "        h_list = h_list[:-1] #Removing the h_n data from the list for convention\n",
    "    \n",
    "        index = 0\n",
    "        grad_HH = np.zeros((self.hidden_size ,self.hidden_size))\n",
    "        grad_IH = np.zeros((self.hidden_size,4))\n",
    "        grad_bias1 = 0\n",
    "    \n",
    "        #Implementation of the derivative chain\n",
    "        for i in reversed(range(1,len(h_list))): # i = n-1,n-2 .... , 0\n",
    "            term = initial_term\n",
    "            for j in range(len(h_list)-1,len(h_list)-index-1,-1): # j = n-1,....,n-1-index\n",
    "    \n",
    "                term = np.dot(term,self.HH_weight) * (1-h_list[j]**2) #term = (term @ WHH) * h[j]\n",
    "    \n",
    "            grad_HH += np.dot(term.T,h_list[i])\n",
    "            #print(\"Delta Grad_HH:\",np.dot((common * term).T,h_list[i]))\n",
    "            grad_IH += np.dot( term.T,x_list[i])\n",
    "            grad_bias1 += np.mean( term * -1)\n",
    "            index += 1\n",
    "\n",
    "        return grad_IH,grad_HH \n",
    "        \n",
    "    \n",
    "    def output_backward(self,dWoh):\n",
    "        \n",
    "        self.OH_weight= self.OH_weight + self.learning_rate*dWoh\n",
    "    \n",
    "    def hh_backward(self,gradient_list):\n",
    "        self.HH_weight = self.HH_weight + self.learning_rate*gradient_list\n",
    "        \n",
    "    def IH_backward(self,gradient_list):\n",
    "        self.IH_weight = self.IH_weight + self.learning_rate*gradient_list\n",
    "        \n",
    "    def Train(self,data,label,batch_size):\n",
    "        startTime = time.time()\n",
    "        correct_predictions2=0\n",
    "        total=0\n",
    "        correct_predictions3=0\n",
    "        self.batch_size=batch_size\n",
    "        for epoch in range(15):\n",
    "            print(\"epoch: \", epoch + 1)\n",
    "            cum_error=0.0\n",
    "            \n",
    "            correct_predictions2=0\n",
    "            for idx in range(3000):\n",
    "                sample_data=data[idx,:,:]\n",
    "                bias=-1 * np.ones((sample_data.shape[0], 1))\n",
    "                biased_sample=np.hstack((sample_data,bias))\n",
    "                self.batch_error=0.0\n",
    "                correct_predictions1=0\n",
    "                for time_idx in range(int(150/self.batch_size)):\n",
    "                    total+=150/self.batch_size\n",
    "                    datas=biased_sample[int(self.batch_size*time_idx):int(self.batch_size*(time_idx+1))]\n",
    "                    labels=label[idx]\n",
    "                    h_list,output_list,error,grad_HO,input_list,output,correct_predictions=self.forward_propagation(datas, labels,self.batch_size)\n",
    "                    self.batch_error+=np.sum(error)\n",
    "                    correct_predictions1+=correct_predictions\n",
    "                    #print(\"Batch error {i} {error}\".format(i=time_idx,error=error))\n",
    "                    self.delta_weights=np.zeros((6, 50))                    \n",
    "                    \n",
    "                    grad_IH,grad_HH=self.gradient(output,labels,h_list,input_list)\n",
    "                    #print(list_gradient[1].shape)\n",
    "                    #grad_IH,grad_HH = self.calculate_grad(y_i,label,h_list,x_list)\n",
    "                    max_gradient_norm = 0.5  # Adjust this threshold as needed\n",
    "            \n",
    "                    # Inside your weight update step\n",
    "                    grad_HO_clipped = np.clip(grad_HO, -max_gradient_norm, max_gradient_norm)\n",
    "                    grad_HH_clipped = np.clip(grad_HH, -max_gradient_norm, max_gradient_norm)\n",
    "                    grad_IH_clipped = np.clip(grad_IH, -max_gradient_norm, max_gradient_norm)\n",
    "            \n",
    "                    #print(\"---------------- Gradients---------------\")\n",
    "                    #print(\"Sum of Unclipped Grad_HH:\",np.sum(grad_HH),\"Sum of Clipped Grad_HH:\",np.sum(grad_HH_clipped))\n",
    "                    #print(\"Sum of Unclipped Grad_IH:\",np.sum(grad_IH),\"Sum of Clipped Grad_IH:\",np.sum(grad_IH_clipped))\n",
    "            \n",
    "                    #Updating the weights at the end of the batch\n",
    "                    self.OH_weight -= self.learning_rate * grad_HO/batch_size\n",
    "                    self.HH_weight -= self.learning_rate * grad_HH_clipped/batch_size\n",
    "                    self.IH_weight -= self.learning_rate * grad_IH_clipped/batch_size\n",
    "                    \n",
    "                #self.batch_error=(self.batch_error/batch_size)\n",
    "                correct_predictions2+=correct_predictions1\n",
    "                cum_error+=np.sum((self.batch_error/50))\n",
    "                #print(\"Epoch error {i} {error}\".format(i=epoch,error=batch_error))\n",
    "            correct_predictions3+=correct_predictions2\n",
    "            print(cum_error)\n",
    "        print(\"Train error\",100*correct_predictions3/total)\n",
    "\n",
    "        \n",
    "    def Tanh_activation(self,x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def sigmoid_activation(self,x):\n",
    "        y = expit(x)\n",
    "        return y\n",
    "    \n",
    "    def Tanh_activation_derivative(self,x):\n",
    "        return (1/2)*(1-x*x)\n",
    "    \n",
    "    def sigmoid_activation_derivative(self,x):\n",
    "        return x-x*x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "9584.829579249212\n",
      "epoch:  2\n",
      "8177.657916647001\n",
      "epoch:  3\n",
      "7708.037334545171\n",
      "epoch:  4\n",
      "7548.950924847091\n",
      "epoch:  5\n",
      "7880.690275319436\n",
      "epoch:  6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-b07f88ff13fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdeneme9\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHAR2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdeneme9\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitilaze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdeneme9\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-124-df2dbfdce754>\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(self, data, label, batch_size)\u001b[0m\n\u001b[0;32m    111\u001b[0m                     \u001b[1;31m# Inside your weight update step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                     \u001b[0mgrad_HO_clipped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_HO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmax_gradient_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_gradient_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                     \u001b[0mgrad_HH_clipped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_HH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmax_gradient_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_gradient_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m                     \u001b[0mgrad_IH_clipped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_IH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mmax_gradient_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_gradient_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mclip\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mclip\u001b[1;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n\u001b[0;32m   2082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m     \"\"\"\n\u001b[1;32m-> 2084\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'clip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_clip\u001b[1;34m(a, min, max, out, casting, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m             um.maximum, a, min, out=out, casting=casting, **kwargs)\n\u001b[0;32m    130\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         return _clip_dep_invoke_with_casting(\n\u001b[0m\u001b[0;32m    132\u001b[0m             um.clip, a, min, max, out=out, casting=casting, **kwargs)\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_clip_dep_invoke_with_casting\u001b[1;34m(ufunc, out, casting, *args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# try to deal with broken casting rules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_UFuncOutputCastingError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Numpy 1.17.0, 2019-02-24\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deneme9=HAR2()\n",
    "deneme9.initilaze(50,0.001)\n",
    "deneme9.Train(trX,trY,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test(deneme9.HH_weight,deneme9.OH_weight,deneme9.IH_weight,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAR3:\n",
    "\n",
    "    def initilaze(self,hidden_size,learning_rate):\n",
    "        \n",
    "        self.IH_weight = np.random.uniform(-0.01, 0.01, size=(hidden_size, 4))\n",
    "        self.HH_weight = np.random.uniform(-0.01, 0.01, size=(hidden_size, hidden_size))\n",
    "        self.OH_weight = np.random.uniform(-0.01, 0.01, size=(6, hidden_size+1))\n",
    "        self.learning_rate = learning_rate\n",
    "        self.hidden_size = hidden_size\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def forward_propagation(self,datas,labels,batch_size):\n",
    "        EPSILON = 1e-10\n",
    "        grad_HO = 0\n",
    "        cost = 0\n",
    "        h_list = np.zeros((self.batch_size,1,self.hidden_size))\n",
    "        input_list = np.zeros((self.batch_size,1,4))\n",
    "        output_list = np.zeros((self.batch_size,1,6))  \n",
    "        feedback=np.zeros((self.hidden_size,1))\n",
    "        error=0.0\n",
    "        correct_predictions=0\n",
    "        for i in range(self.batch_size):\n",
    "            data=datas[i].reshape(1,4)\n",
    "            input_list[i]=data\n",
    "            v_1= np.dot(self.IH_weight,data.T) + np.dot(self.HH_weight.T,feedback)\n",
    "            h_i=self.Tanh_activation(v_1)\n",
    "            feedback=h_i\n",
    "            h_list[i]=feedback.T\n",
    "            bias=-1 * np.ones((1, 1))\n",
    "            biased_h_i=np.concatenate((h_i.T,bias),axis=1)\n",
    "            y_input = biased_h_i\n",
    "            v_2= np.dot(self.OH_weight,y_input.T)\n",
    "            output=self.sigmoid_activation(v_2)\n",
    "            labels=labels.reshape(6,1)\n",
    "            correct_predictions += np.sum(np.argmax(output, axis=0) == np.argmax(labels, axis=0))\n",
    "            grad_HO +=  np.dot((output-labels), biased_h_i)\n",
    "            error += -labels * np.log10(np.clip(output, EPSILON, 1 - EPSILON)) -(1 - labels) * np.log10(np.clip(1 - output, EPSILON, 1 - EPSILON))\n",
    "\n",
    "            output_list[i]=output.T\n",
    "\n",
    "        return h_list,output_list,error,grad_HO,input_list,output,correct_predictions\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def gradient(self,y_n,d_n,h_list,x_list): #BPTT algorithm for updating WIH and WHH\n",
    "        #h_list = [h0,h1,....,hn]\n",
    "        h_n = h_list[-1]\n",
    "    \n",
    "        common = np.dot((y_n.T - d_n),self.OH_weight [:, :-1]) # 1x6 @ 6xN -> 1xN\n",
    "    \n",
    "        initial_term = common * (1-h_n**2)\n",
    "    \n",
    "        h_list = h_list[:-1] #Removing the h_n data from the list for convention\n",
    "    \n",
    "        index = 0\n",
    "        grad_HH = np.zeros((self.hidden_size ,self.hidden_size))\n",
    "        grad_IH = np.zeros((self.hidden_size,4))\n",
    "        grad_bias1 = 0\n",
    "    \n",
    "        #Implementation of the derivative chain\n",
    "        for i in reversed(range(1,len(h_list))): # i = n-1,n-2 .... , 0\n",
    "            term = initial_term\n",
    "            for j in range(len(h_list)-1,len(h_list)-index-1,-1): # j = n-1,....,n-1-index\n",
    "    \n",
    "                term = np.dot(term,self.HH_weight) * (1-h_list[j]**2) #term = (term @ WHH) * h[j]\n",
    "    \n",
    "            grad_HH += np.dot(term.T,h_list[i])\n",
    "            #print(\"Delta Grad_HH:\",np.dot((common * term).T,h_list[i]))\n",
    "            grad_IH += np.dot( term.T,x_list[i])\n",
    "            grad_bias1 += np.mean( term * -1)\n",
    "            index += 1\n",
    "\n",
    "        return grad_IH,grad_HH \n",
    "        \n",
    "    \n",
    "    def output_backward(self,dWoh):\n",
    "        \n",
    "        self.OH_weight= self.OH_weight + self.learning_rate*dWoh\n",
    "    \n",
    "    def hh_backward(self,gradient_list):\n",
    "        self.HH_weight = self.HH_weight + self.learning_rate*gradient_list\n",
    "        \n",
    "    def IH_backward(self,gradient_list):\n",
    "        self.IH_weight = self.IH_weight + self.learning_rate*gradient_list\n",
    "        \n",
    "    def Train(self,data,label,batch_size):\n",
    "        startTime = time.time()\n",
    "        correct_predictions2=0\n",
    "        total=0\n",
    "        correct_predictions3=0\n",
    "        self.batch_size=batch_size\n",
    "        for epoch in range(15):\n",
    "            print(\"epoch: \", epoch + 1)\n",
    "            cum_error=0.0\n",
    "            \n",
    "            correct_predictions2=0\n",
    "            for idx in range(3000):\n",
    "                sample_data=data[idx,:,:]\n",
    "                bias=-1 * np.ones((sample_data.shape[0], 1))\n",
    "                biased_sample=np.hstack((sample_data,bias))\n",
    "                self.batch_error=0.0\n",
    "                correct_predictions1=0\n",
    "                for time_idx in range(int(150/self.batch_size)):\n",
    "                    total+=150/self.batch_size\n",
    "                    datas=biased_sample[int(self.batch_size*time_idx):int(self.batch_size*(time_idx+1))]\n",
    "                    labels=label[idx]\n",
    "                    h_list,output_list,error,grad_HO,input_list,output,correct_predictions=self.forward_propagation(datas, labels,self.batch_size)\n",
    "                    self.batch_error+=np.sum(error)\n",
    "                    correct_predictions1+=correct_predictions\n",
    "                    #print(\"Batch error {i} {error}\".format(i=time_idx,error=error))\n",
    "                    self.delta_weights=np.zeros((6, 50))                    \n",
    "                    \n",
    "                    grad_IH,grad_HH=self.gradient(output,labels,h_list,input_list)\n",
    "                    #print(list_gradient[1].shape)\n",
    "                    #grad_IH,grad_HH = self.calculate_grad(y_i,label,h_list,x_list)\n",
    "                    max_gradient_norm = 0.5  # Adjust this threshold as needed\n",
    "            \n",
    "                    # Inside your weight update step\n",
    "                    grad_HO_clipped = np.clip(grad_HO, -max_gradient_norm, max_gradient_norm)\n",
    "                    grad_HH_clipped = np.clip(grad_HH, -max_gradient_norm, max_gradient_norm)\n",
    "                    grad_IH_clipped = np.clip(grad_IH, -max_gradient_norm, max_gradient_norm)\n",
    "            \n",
    "                    #print(\"---------------- Gradients---------------\")\n",
    "                    #print(\"Sum of Unclipped Grad_HH:\",np.sum(grad_HH),\"Sum of Clipped Grad_HH:\",np.sum(grad_HH_clipped))\n",
    "                    #print(\"Sum of Unclipped Grad_IH:\",np.sum(grad_IH),\"Sum of Clipped Grad_IH:\",np.sum(grad_IH_clipped))\n",
    "            \n",
    "                    #Updating the weights at the end of the batch\n",
    "                    self.OH_weight -= self.learning_rate * grad_HO/batch_size\n",
    "                    self.HH_weight -= self.learning_rate * grad_HH_clipped/batch_size\n",
    "                    self.IH_weight -= self.learning_rate * grad_IH_clipped/batch_size\n",
    "                    \n",
    "                #self.batch_error=(self.batch_error/batch_size)\n",
    "                correct_predictions2+=correct_predictions1\n",
    "                cum_error+=np.sum((self.batch_error/50))\n",
    "                #print(\"Epoch error {i} {error}\".format(i=epoch,error=batch_error))\n",
    "            correct_predictions3+=correct_predictions2\n",
    "            print(cum_error)\n",
    "        print(\"Train error\",100*correct_predictions3/total)\n",
    "\n",
    "        \n",
    "    def Tanh_activation(self,x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def sigmoid_activation(self,x):\n",
    "        y = expit(x)\n",
    "        return y\n",
    "    \n",
    "    def Tanh_activation_derivative(self,x):\n",
    "        return (1/2)*(1-x*x)\n",
    "    \n",
    "    def sigmoid_activation_derivative(self,x):\n",
    "        return x-x*x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "1933.5060357555421\n",
      "epoch:  2\n",
      "1581.4346947841432\n",
      "epoch:  3\n",
      "1533.266350840202\n",
      "epoch:  4\n",
      "1514.3974871418202\n",
      "epoch:  5\n",
      "1495.8431825126845\n",
      "epoch:  6\n",
      "1467.2247605927225\n",
      "epoch:  7\n",
      "1431.202616376623\n",
      "epoch:  8\n",
      "1402.1424229263137\n",
      "epoch:  9\n",
      "1384.1146598197502\n",
      "epoch:  10\n",
      "1371.9087695859712\n",
      "epoch:  11\n",
      "1361.8922793871648\n",
      "epoch:  12\n",
      "1352.593348586671\n",
      "epoch:  13\n",
      "1343.684212733349\n",
      "epoch:  14\n",
      "1335.4319066996782\n",
      "epoch:  15\n",
      "1328.1647720618726\n",
      "Train error 32.37837037037037\n"
     ]
    }
   ],
   "source": [
    "deneme10=HAR3()\n",
    "deneme10.initilaze(50,0.001)\n",
    "deneme10.Train(trX,trY,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 35.05444444444444\n",
      "Top-2 Accuracy: % 46.16888888888889\n",
      "Top-3 Accuracy: % 65.17333333333333\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme10.HH_weight,deneme10.OH_weight,deneme10.IH_weight,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "8163.008148929671\n",
      "epoch:  2\n",
      "7208.699751090073\n",
      "epoch:  3\n",
      "7803.879650048873\n",
      "epoch:  4\n",
      "7950.256029598205\n",
      "epoch:  5\n",
      "7008.193046370538\n",
      "epoch:  6\n",
      "6823.833464930976\n",
      "epoch:  7\n",
      "6622.357222655244\n",
      "epoch:  8\n",
      "6524.917829049795\n",
      "epoch:  9\n",
      "6599.113355228023\n",
      "epoch:  10\n",
      "6563.621184366706\n",
      "epoch:  11\n",
      "6498.4357889587845\n",
      "epoch:  12\n",
      "6561.0906574474875\n",
      "epoch:  13\n",
      "6731.450833034972\n",
      "epoch:  14\n",
      "6756.77434603831\n",
      "epoch:  15\n",
      "6711.932075913851\n",
      "Train error 40.22910617283951\n"
     ]
    }
   ],
   "source": [
    "deneme11=HAR3()\n",
    "deneme11.initilaze(50,0.005)\n",
    "deneme11.Train(trX,trY,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 18.32777777777778\n",
      "Top-2 Accuracy: % 51.14222222222222\n",
      "Top-3 Accuracy: % 64.4211111111111\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme11.HH_weight,deneme11.OH_weight,deneme11.IH_weight,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "9571.126465790072\n",
      "epoch:  2\n",
      "8192.465041327856\n",
      "epoch:  3\n",
      "7764.4040843774965\n",
      "epoch:  4\n",
      "7574.158162506186\n",
      "epoch:  5\n",
      "8111.579809643991\n",
      "epoch:  6\n",
      "8355.290198863346\n",
      "epoch:  7\n",
      "8057.638361032556\n",
      "epoch:  8\n",
      "8234.725056320762\n",
      "epoch:  9\n",
      "8106.274454641604\n",
      "epoch:  10\n",
      "7969.076744208654\n",
      "epoch:  11\n",
      "7824.971804967103\n",
      "epoch:  12\n",
      "7714.185126898147\n",
      "epoch:  13\n",
      "7652.900359653235\n",
      "epoch:  14\n",
      "7638.61429791431\n",
      "epoch:  15\n",
      "7706.28827649167\n",
      "Train error 35.54038518518519\n"
     ]
    }
   ],
   "source": [
    "deneme12=HAR3()\n",
    "deneme12.initilaze(50,0.001)\n",
    "deneme12.Train(trX,trY,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 17.855555555555554\n",
      "Top-2 Accuracy: % 32.92333333333333\n",
      "Top-3 Accuracy: % 51.38333333333334\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme12.HH_weight,deneme12.OH_weight,deneme12.IH_weight,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "10614.895717846639\n",
      "epoch:  2\n",
      "9239.493269763365\n",
      "epoch:  3\n",
      "9118.419076988264\n",
      "epoch:  4\n",
      "8980.991832961985\n",
      "epoch:  5\n",
      "8732.315554388031\n",
      "epoch:  6\n",
      "8461.362991134773\n",
      "epoch:  7\n",
      "8281.597826461373\n",
      "epoch:  8\n",
      "8167.649888692043\n",
      "epoch:  9\n",
      "8079.6180648838545\n",
      "epoch:  10\n",
      "8002.03037248684\n",
      "epoch:  11\n",
      "7932.784255177374\n",
      "epoch:  12\n",
      "7874.534110138276\n",
      "epoch:  13\n",
      "7827.816941936407\n",
      "epoch:  14\n",
      "7789.504286651167\n",
      "epoch:  15\n",
      "7755.369006162909\n",
      "Train error 302.6431111111111\n"
     ]
    }
   ],
   "source": [
    "deneme13=HAR3()\n",
    "deneme13.initilaze(50,0.001)\n",
    "deneme13.Train(trX,trY,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 37.45777777777778\n",
      "Top-2 Accuracy: % 47.69555555555556\n",
      "Top-3 Accuracy: % 65.21111111111111\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme13.HH_weight,deneme13.OH_weight,deneme13.IH_weight,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "9356.055672929162\n",
      "epoch:  2\n",
      "8217.73491389517\n",
      "epoch:  3\n",
      "7829.118776064981\n",
      "epoch:  4\n",
      "7598.173791969922\n",
      "epoch:  5\n",
      "7378.552246630363\n",
      "epoch:  6\n",
      "7991.925600442427\n",
      "epoch:  7\n",
      "7512.698766233028\n",
      "epoch:  8\n",
      "7259.147429001301\n",
      "epoch:  9\n",
      "7146.927730427255\n",
      "epoch:  10\n",
      "7014.674958512691\n",
      "epoch:  11\n",
      "7041.126390609351\n",
      "epoch:  12\n",
      "7709.44593348968\n",
      "epoch:  13\n",
      "7311.65610449664\n",
      "epoch:  14\n",
      "7129.092605411075\n",
      "epoch:  15\n",
      "7061.724644916814\n",
      "Train error 339.8813333333333\n"
     ]
    }
   ],
   "source": [
    "deneme14=HAR3()\n",
    "deneme14.initilaze(50,0.005)\n",
    "deneme14.Train(trX,trY,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 16.924444444444443\n",
      "Top-2 Accuracy: % 33.33333333333333\n",
      "Top-3 Accuracy: % 50.0\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme14.HH_weight,deneme14.OH_weight,deneme14.IH_weight,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "9513.672442817233\n",
      "epoch:  2\n",
      "8078.514955509418\n",
      "epoch:  3\n",
      "7735.556254227175\n",
      "epoch:  4\n",
      "7848.689256585519\n",
      "epoch:  5\n",
      "7685.568495213353\n",
      "epoch:  6\n",
      "7530.616743321824\n",
      "epoch:  7\n",
      "7558.908799530256\n",
      "epoch:  8\n",
      "7431.650792192024\n",
      "epoch:  9\n",
      "7248.842426726276\n",
      "epoch:  10\n",
      "7115.502947330931\n",
      "epoch:  11\n",
      "7100.58043379533\n",
      "epoch:  12\n",
      "7037.946408711767\n",
      "epoch:  13\n",
      "6920.852722499561\n",
      "epoch:  14\n",
      "7022.0751423666115\n",
      "epoch:  15\n",
      "7252.870212584469\n",
      "Train error 38.078064197530864\n"
     ]
    }
   ],
   "source": [
    "deneme15=HAR3()\n",
    "deneme15.initilaze(100,0.001)\n",
    "deneme15.Train(trX,trY,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 16.668888888888887\n",
      "Top-2 Accuracy: % 33.336666666666666\n",
      "Top-3 Accuracy: % 50.00444444444444\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme15.HH_weight,deneme15.OH_weight,deneme15.IH_weight,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "9266.94479573958\n",
      "epoch:  2\n",
      "8118.0748028522885\n",
      "epoch:  3\n",
      "7805.884257173857\n",
      "epoch:  4\n",
      "7652.354318514225\n",
      "epoch:  5\n",
      "7721.027592016223\n",
      "epoch:  6\n",
      "7407.9613363947965\n",
      "epoch:  7\n",
      "7166.021125395094\n",
      "epoch:  8\n",
      "7138.981352705312\n",
      "epoch:  9\n",
      "7215.860816527946\n",
      "epoch:  10\n",
      "7153.815744056676\n",
      "epoch:  11\n",
      "7075.185635012642\n",
      "epoch:  12\n",
      "7034.465281910015\n",
      "epoch:  13\n",
      "6970.1620108192565\n",
      "epoch:  14\n",
      "6919.405813229523\n",
      "epoch:  15\n",
      "7472.702986348557\n",
      "Train error 344.7080888888889\n"
     ]
    }
   ],
   "source": [
    "deneme16=HAR3()\n",
    "deneme16.initilaze(100,0.005)\n",
    "deneme16.Train(trX,trY,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 16.66777777777778\n",
      "Top-2 Accuracy: % 38.49333333333333\n",
      "Top-3 Accuracy: % 50.18666666666667\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme16.HH_weight,deneme16.OH_weight,deneme16.IH_weight,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "10605.869189450776\n",
      "epoch:  2\n",
      "9219.224204794715\n",
      "epoch:  3\n",
      "9057.605826763864\n",
      "epoch:  4\n",
      "8836.517812428438\n",
      "epoch:  5\n",
      "8536.148806929554\n",
      "epoch:  6\n",
      "8316.843666504901\n",
      "epoch:  7\n",
      "8186.571345446454\n",
      "epoch:  8\n",
      "8088.986513804356\n",
      "epoch:  9\n",
      "8004.532028960151\n",
      "epoch:  10\n",
      "7932.019636859201\n",
      "epoch:  11\n",
      "7874.796335526782\n",
      "epoch:  12\n",
      "7832.44348313446\n",
      "epoch:  13\n",
      "7800.336503444667\n",
      "epoch:  14\n",
      "7773.143390058928\n",
      "epoch:  15\n",
      "7747.17517128542\n",
      "Train error 309.09884444444447\n"
     ]
    }
   ],
   "source": [
    "deneme17=HAR3()\n",
    "deneme17.initilaze(100,0.001)\n",
    "deneme17.Train(trX,trY,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 37.230000000000004\n",
      "Top-2 Accuracy: % 48.11111111111111\n",
      "Top-3 Accuracy: % 65.07111111111111\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme17.HH_weight,deneme17.OH_weight,deneme17.IH_weight,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      "8031.779009488543\n",
      "epoch:  2\n",
      "7105.367153023587\n",
      "epoch:  3\n",
      "7376.171920781407\n",
      "epoch:  4\n",
      "6258.336893022159\n",
      "epoch:  5\n",
      "6993.540905516558\n",
      "epoch:  6\n",
      "7895.153560308152\n",
      "epoch:  7\n",
      "7858.917686190844\n",
      "epoch:  8\n",
      "7926.743114194737\n",
      "epoch:  9\n",
      "8014.8292217242915\n",
      "epoch:  10\n",
      "7920.525309559502\n",
      "epoch:  11\n",
      "7924.311366271285\n",
      "epoch:  12\n",
      "7784.043346183163\n",
      "epoch:  13\n",
      "8051.037077564447\n",
      "epoch:  14\n",
      "8342.595831944724\n",
      "epoch:  15\n",
      "8210.691130649644\n",
      "Train error 36.385432098765435\n"
     ]
    }
   ],
   "source": [
    "deneme18=HAR3()\n",
    "deneme18.initilaze(100,0.005)\n",
    "deneme18.Train(trX,trY,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: % 19.851111111111113\n",
      "Top-2 Accuracy: % 34.67333333333333\n",
      "Top-3 Accuracy: % 52.32555555555556\n"
     ]
    }
   ],
   "source": [
    "data_test(deneme18.HH_weight,deneme18.OH_weight,deneme18.IH_weight,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
